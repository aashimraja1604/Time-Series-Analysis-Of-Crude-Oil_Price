# -*- coding: utf-8 -*-
"""Time Series Analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gyTBCLLxyEkKT58ju9DzAF_cseUqi94Q

# **Project Overview**
My project involves conducting a time series analysis of crude oil price changes over a given period and making predictions about the future based on historical data.

# **Approach**
I am utilizing Long Short-Term Memory `(LSTM)` models for deep learning on extended historical data. These models prove effective in capturing patterns over prolonged periods, making them particularly suitable for this analysis.

# **Project Workflow**
The project is structured into three main sections:
1. Data Acquisition: Gathering the necessary data from the source.
2. Data Processing: Filtering and preparing the data for analysis.
3. Prediction: Utilizing LSTM models to make future predictions based on the analyzed historical data.
"""

# Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
import math

"""# **Data Scraping**
I gather data from the website `'https://www.eia.gov/'` by utilizing an API key. To obtain the key, I navigate to `EIA Data Sets > Petroleum > Prices > Spot Prices`.
The link where I get the data
`https://www.eia.gov/dnav/pet/hist/RCLC1D.htm`
"""

#Getting data of crude price
df = pd.read_excel('/content/Crude oil Data.xlsx')

df

"""## **Filtering Data**
- On this step I am renaming the all columns

"""

df = df.rename(columns={"Cushing, OK Crude Oil Future Contract 1 (Dollars per Barrel)": "Value"})

df = df.set_index('Date')

df

"""- Here we looking the crude oil price is changing from past 30 years"""

df.plot(figsize = (15,7))

"""## **Extracting Crude Oil Prices:**
  - Our objective is to retrieve the value index.
  - Determine the length and data type of the values.

- Normalizing Using StandardScaler:
  - Utilizing the `StandardScaler` library for range normalization.

- Data Extraction and Storage:
  - Extracting data values.
  - Storing the extracted values in DF1 for subsequent analysis.
"""

#Getting values of crude Price
df1 = df.reset_index()['Value']

df1

"""- Here I scaling the data
- Here I scaling complete data not just seprating , training or testing the data
- I am using standard scaler at this point
"""

#Scaling the data and for scaling I using the standardScaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))

df1.shape

df1

"""### **Now you can see it has been scaled by using StandardScaler itself and normalize the data**

"""

plt.figure(figsize=(15,7))
plt.plot(df.index,df1)

"""# **Deciding the time window**
- For window I am getting 100 days.
- Here my assumption is that 100 past data affecting by 101 day
"""

w = int(input(' Enter Window Size: '))

"""## **Here I spearting the training data and testing data**
- I am using around 96% of complete data as the training set and last 4% testing set
"""

training_size = int(len(df1)*0.96)
test_size = len(df1) - training_size
train_data,test_data = df1[0:training_size+w,:],df1[training_size:len(df1),:]

train_data.shape, test_data.shape

"""**Now you can see my training data and testing data**"""

plt.plot(df.index[:training_size+100],train_data)

"""## **Creating the data set**
- This function taking the data set as an input and it istaking time step as input BY Default I have set 100 sets.
- After that I am making two list `List X` and `List Y`
"""

def create_dataset(dataset,time_step = 1):
    dataX, dataY = [],[]

    for i in range(len(dataset)-time_step):
        a = dataset[i:(i+time_step),0] #i=0 then 0,1,2,3,4 will be x and y=4

        dataX.append(a)
        dataY.append(dataset[i+time_step,0])

    return np.array(dataX),np.array(dataY)

"""- Now I am using the last function I am creating the data set like
`X_train`,`Y_train`,`X_test` and `Y_test`
"""

time_step = w
#Using 100 consecutive values predecting 101th value
#f1--------f100 =X
#f101 = y
X_train, y_train = create_dataset(train_data,time_step)
X_test, y_test = create_dataset(test_data,time_step)

"""- Here I showing the data shape of my extend and `X_train` and `X_test` is `8698` to `100`
- On this time of point that is presnt inside two dimensional array by using .shape
"""

#Shape of X_train and X_test
X_train.shape,X_test.shape
#Now it is 2D array

"""## Making the data 3D"""

#Making the data into 3D
X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)

X_train.shape,X_test.shape

"""## This is 3D arrays"""

X_train

"""**I made a small model here just used 50-50 neurons becouse I don't have GPU support and if I want to extend it taking lot of time.**
- Here I just used LSTM and final there i'm adding a dense layer that will be giving my ouput or that is giving my forcasted value
- Than I'm using the mean squared error and optimizar to using adam
"""

model = Sequential() #Sequential model
model.add(LSTM(50,return_sequences = True, input_shape=(100,1))) #Input shape of batch
model.add(LSTM(50,return_sequences = True))
model.add(LSTM(50))
model.add(Dense(1))
model.compile(loss = 'mean_squared_error', optimizer = 'adam')

"""#### On this point our model is looking like this and this having `50851` parameters"""

model.summary()

"""### Now I am fitting my model on X train and Y train validation data will be accessed and white test and 10 new book so that it will take less number of times less."""

model.fit(X_train,y_train,validation_data= (X_test,y_test),epochs= 1,batch_size =128, verbose =1)

"""- Now I got a train predictor and trained test predict from my model"""

train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

"""**Now I have to invest transform that particular by using scalar that we have used for scaling data**"""

train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)

"""**Now in this step i'm just calculating the mean square root error that we obviously will come high value becouse we have went to 10 epoch and our `LSTM` model is also small**"""

from sklearn.metrics import mean_squared_error
math.sqrt(mean_squared_error(y_train,train_predict))

math.sqrt(mean_squared_error(y_test,test_predict))

train_predict.shape

test_predict.shape

"""- Now just few step I'm making the data frame for my predicting values and my actual value and it's all are simle python code"""

a = train_predict.reshape(train_predict.shape[0],)
b = test_predict.reshape(test_predict.shape[0],)
#Here we do total
c = list(a)+list(b)

len(c)

t = []
for i in range(100):
    t.append(np.NaN)

d = t+c

len(d)

df['Predicted Price'] =d

"""Below cell is showing the data frame and on the right first colomn is initial or actual values and on the right side it is the my predicteing values and will be showing `NaN` and why they showing `NaN` the reason is that, first 100 values we have taken for 101th values,So those hundred values is not predicted. So the first 100 values remain `NaN`"""

df

"""## **Ploting my actual values and my predicted values for training set and testing set**
- On this point we haven't done any forecasting
"""

plt.figure(figsize = (16,7))
plt.grid(True)
plt.title('Crude oil Price Forecasting Training and Validation')
plt.plot(df.index,df['Value'],label = "Original Value", c = "blue")
plt.plot(df[:train_predict.shape[0]+w].index,df['Predicted Price'][:train_predict.shape[0]+w],label = "Predicting Training Price", c='red')
plt.plot(df.index[train_predict.shape[0]+100:],df['Predicted Price'][train_predict.shape[0]+w:],label = "Predicting Validating Price",c ='green')
plt.axvline(df.index[train_predict.shape[0]+w], color='black',lw=3)

plt.legend()

"""**Now I'm using this model for forecasting purpose because till this point I have data it just looking good is predicting for the data that I have.**

** Forecasting in Future**
- We have data till date `2024-01-17` to `1987-05-20`
- Now I want the forcasted value after `2024-01-18`
"""

df

"""### First i'm making the data frame out of it first 100 values and reperseting that `CD`"""

cd = df[100:] #cd = Crude Oil

cd

"""## Test data shape"""

test_data.shape

"""- On this step I am going to use last 100 point and will we predicting the output of `2023-01-201`"""

#For next one day price, Last 100 days data is needed
x_input = test_data[-100:].reshape(1,-1)
x_input.shape

"""- Here I am able to calculate the crude price for `20th of Jan`"""

x_input

temp_input = list(x_input)

temp_input

temp_input = temp_input[0].tolist()

temp_input

"""## Demonstrate predictions for next 30 Days:
- First time else loop willl run, reshape is done and after tht it passes to model and prediction is done for 101st day, after that this 101th day data is added in final output. And this 101 day data will be used in previous input list. Now the input list will have 101 elements so the if loop will run and the data for first day is fropped so that we can take data from day 2 to day 101 and predict data for day 102, in a similary way the loopa qill run for 30 days

- for i=0(first loop in while). the else loop will run because 100 elements are present in temp_input. After adding data for 101 day from forecasting. the if loop will run and 1st data will be excluded
"""

lst_output = []
n_steps = 100
i=0
# Here Yhat is the cure price of 101th day or next day

while i<30: #For 30 days forecast
    if(len(temp_input)>100):
        #print(temp_input)
        x_input = np.array(temp_input[1:]) # Taking x_input values from 2nd value onward
        print('{} day input {}'.format(i,x_input))
        x_input = x_input.reshape(1,-1)
        x_input = x_input.reshape((1, n_steps,1)) #making tensor of 1 batch,with n rows and 1 column
        #print(x_input)
        yhat = model.predict(x_input,verbose=1)
        print('{} day output {}'.format(i,yhat))
        temp_input.extend(yhat[0].tolist()) # Adding forecasting value to the temp_input.
        temp_input = temp_input[1:] # Because after adding the above yhat[0],total number of elements
        #print(temp_input)
        lst_output.extend(yhat.tolist()) #Adding 101 day forcast to output forecasting list
        i = i+1
    else: #first loop will go inside this
        x_input = x_input.reshape((1,n_steps,1)) #Last 100 days data
        yhat= model.predict(x_input,verbose = 0) #Taking prediction from model
        print(yhat[0])
        temp_input.extend(yhat[0].tolist()) #Adding predicted value of 101 day in temp_input
        print(len(temp_input))
        lst_output.extend(yhat.tolist()) #Adding 101 day forecast to output forecasting list
        i =i+1
print(lst_output)

forecast = scaler.inverse_transform(lst_output)

forecast.shape

forecast = forecast.reshape(30,)

cd

"""- Making the some synthetic data dates for next 30 days byusing PD.data_range"""

t_fut = pd.date_range('2024-01-17 00:00:00+00:00', periods=30)

t_fut

"""### Making the data frame of this particular forecasted values in `CD4`"""

cd4 = pd.DataFrame({'Forecast Price':forecast},index = t_fut)
cd4

"""## Ploting all the the things together
- In this ploting I showing the data from Jan 2022 to current date+30 future prediction

**Green row showing the my testing data and black is showing my forecasted 30 days data and you can see it is geting some of the trends from previous values**
"""

plt.figure(figsize = (16,7))
plt.grid(True)
plt.title('Crude oil Price Forecasting Training and Validation')
# plt.plot(df.index,df['Value'],label = "Original Value", c = 'blue')
# plt.plot(df[:train_predict.shape[0]+w].index,df['Predicted Price'][:train_predict.shape[0]+w],label = "Predicting Training Price", c='red')
plt.plot(df.index[train_predict.shape[0]+100:],df['Predicted Price'][train_predict.shape[0]+w:],label = "Predicting Validating Price",c ='green')

plt.plot(cd4.index,cd4['Forecast Price'],label = 'Forecasted Price',c ='black')

plt.axvline(df.index[train_predict.shape[0]+w], color='black',lw=3)
plt.axvline(cd4.index[0],color='black', lw=2)

plt.legend()

"""In this ploting I showing the data from `04 April 1983` to current date+30 for future prediction"""

plt.figure(figsize = (16,7))
plt.grid(True)
plt.title('Crude oil Price Forecasting Training and Validation')
plt.plot(df.index,df['Value'],label = "Original Value", c = 'blue')
plt.plot(df[:train_predict.shape[0]+w].index,df['Predicted Price'][:train_predict.shape[0]+w],label = "Predicting Training Price", c='red')
plt.plot(df.index[train_predict.shape[0]+100:],df['Predicted Price'][train_predict.shape[0]+w:],label = "Predicting Validating Price",c ='green')

plt.plot(cd4.index,cd4['Forecast Price'],label = 'Forecasted Price',c ='black')

plt.axvline(df.index[train_predict.shape[0]+w], color='black',lw=3)
plt.axvline(cd4.index[0],color='black', lw=2)

plt.legend()

"""## Drabacks of LSTM univarite forcating
- Crude oil price forecasting is not only depend on historical data it also fluctuates with the geopolitics and more factors like, War,Natural Disasters, and accidents etc.

- In this model I haven't take care of those geopolitics things in these particular model.

- We haven't take care of geopolitics fluctuates because of that it's not proper correct
"""